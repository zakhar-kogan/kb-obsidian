# Contingent planning notes
## [A Multi-Path Compilation Approach to Contingent Planning](https://tzin.bgu.ac.il/~shanigu/Publications/aaai12-28.pdf)

We have environment ${F,A,I,O,G}$
We have locations ${L_1, ..., L_n}$
We have preconditions for actions ${P_{a1}, P_{a2}, ..., P_{an}}$
- Can we look for the worst possible situations, i.e. the situations where another agent can definitely interfere with plans?
- For planning the best path - maybe the other approach will be suitable -> having a critical/best path for $a_i$, and checking for potential stalemates at each step, iterating. however, we must reduce the state and belief space, not do a naive approach
- How can we reduce the statespace?
- How can we transform the problem/state space into a causal graph? e.g. nodes that are 'vector' state spaces, and edges that are changes in, say, one fluent
- How can we eliminate replanning? so that agents are not stuck in their trajectories, but only have the actions they can 
- Recognizing 'patterns' that lead to fails/dead-locks in the state space graph? e.g. _if agent X comes within 2 meters from the right, and carries the box, we will get stuck_ -> need to avoid that
- How do we plan robustly and formally in unknown state-space, building it with agents' sensing step by step? maybe decision graph? e.g. "if i see a box AND another robot AND robot has priority -> i wait" + "if another robot has a box AND i see the litter AND no goal location is sensed/messaged -> I get to the litter location and clean it"

> Contingent planning definition: https://shottr.cc/s/OPnV/SCR-20230907-ook.png

> In current benchmark problems, either the set effects or the set obs are empty. That is, actions either alter the state of the world but provide no information, or they are pure sensing actions that do not alter the state of the world, but this is not a mandatory limitation.

> _A major difficulty of contingent planning is that we can not predict, at planning time, what will be observed follow ing a sensing action. Thus, we cannot predict the agent’s state of knowledge at run-time. At planning time, though, useful knowledge may be gained and leveraged._

> _If s is the initial state, in a deterministic environment, we know what observations the agent will make, and consequently, its state of information at run-time. In particular, given that s is the true world state, we know which states it will be able to distinguish from s_

> _For representing knowledge we need 3 types of proposi tions: propositions that represent the current value of world features, conditioned upon an initial state, propositions that represent whether the agent currently knows the value of world features, given an initial state, and propositions that allow the reasoning about the belief state. For the latter, we maintain propositions that define whether two states s and_ _s0 are distinguishable, i.e., whether the agent has observed a proposition whose value is different in the two states._

> _For belief maintenance and update we use the lazy regression technique suggested by Shani and Brafman (2011), where only the initial belief state is maintained, and queries_ _concerning possible current states are resolved by regressing the query through the action-observation history_

## [Replanning in Domains with Partial Information and Sensing Actions](https://tzin.bgu.ac.il/~shanigu/Publications/sdr-journal11.pdf)

- idea -> using a delta-style/blockchain where only the changes are saved?
- another idea -> using one-hot encoding, or just vectorized representation of a state; where facts are presented as ${[F1, F2, ..., Fn]: [0,1,1,0,0,2,...n]}$ superset
  that way we can present everything in a more compact way
## [Partially Observable Online Contingent Planning Using Landmark Heuristics](https://tzin.bgu.ac.il/~shanigu/Publications/ICAPS2014.pdf)
