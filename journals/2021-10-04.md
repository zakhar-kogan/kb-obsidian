#finance #ethereum #crypto

# [[Uniswap]] v3 pools
https://newsletter.banklesshq.com/p/how-to-automate-uniswap-v3-liquidity
https://vividot-de.fi/entry/Uniswap-V3-Automated-Manager
# [[Uniswap]] v3 on [[Optimism]]
https://newsletter.banklesshq.com/p/a-guide-to-uniswap-on-optimism

#math #mooc
# Mathematical [[economics]] [[Swayam]]

#career #ea
# My current impressions on [[career]] choice for longtermists
https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists

While the jobs I list overlap heavily with the jobs [80,000 Hours lists](https://80000hours.org/key-ideas/#priority-paths), I organize them and conceptualize them differently. [[80,000 Hours]] tends to emphasize "[**paths**](https://80000hours.org/key-ideas/#priority-paths)" to particular roles working on particular causes; by contrast, I emphasize "**aptitudes**" one can build in a wide variety of roles and causes (including non-effective-altruist organizations) and then apply to a wide variety of longtermist-relevant jobs (often with options working on more than one cause). Example aptitudes include: "helping organizations achieve their objectives via good business practices," "evaluating claims against each other," "communicating already-existing ideas to not-yet-sold audiences," etc.
# Some longtermism-relevant [[aptitudes]]
- ## "Organization building, running, and boosting" [[aptitudes]][[1(https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists?utm_source=80%2C000+Hours+mailing+list&utm_campaign=4f086184e8-RESEARCHNEWSLETTER_Oct_2021_1&utm_medium=email&utm_term=0_43bc1ae55c-4f086184e8-352106301#fn-aAvgmw6MqeiaihsEj-1)
  
  **Basic profile:** helping an organization by bringing "generally useful" skills to it. By "generally useful" skills, I mean skills that could help a wide variety of organizations accomplish a wide variety of different objectives. Such skills could include:
- [Business](Business) operations and [[project]] management (including setting objectives, metrics, etc.)
- [[People]] management and [[management]] coaching (some manager jobs require specialized skills, but some just require general management-associated skills)
- Executive leadership (setting and enforcing organization-wide goals, making top-level decisions about budgeting, etc.)
- Recruiting
- [[Fundraising]] and [[marketing]]
- Human resources
- Office management
- Events management
- Assistant and administrative work
- Corporate communications and public relations
- [finance](finance) and accounting
- Corporate law
  
  **Examples:**
  
  Beth Jones (Open Philanthropy Director of Operations); Max Dalton and Joan Gass at CEA; Malo Bourgon at MIRI. (I focused on people in executive roles and gave only a small number of examples, but I could've listed a large percentage of the people currently working at longtermism-focused organizations, as well as people working at not-explicitly-longtermist organizations doing work that's important by longtermist lights. In general, my examples will be illustrative and focused on relatively simple/"pure" cases of someone focusing on a single aptitude; I don't think people should read into any "exclusions.")
  
  In many cases, early-career work in one specialization can give you some exposure to others. It's often possible to move between the different specializations and try different things. (The last three listed - communications, finance/accounting, and law - are probably the least like this.)
  
  I'm especially positive on joining promising, small-but-growing organizations. In this sort of organization, you often get a chance to try many different things, and can get a rich exposure to many facets of helping an organization succeed. This can be an especially good way to get experience with people management and project management, which are often very generally applicable and in-demand skills across organizations. Coming into such a company in whatever role is available, and then being flexible and simply focused on helping the company succeed, can be a good learning experience that helps with both identifying and skilling up at good-fit aptitudes.
## Political and bureaucratic aptitudes

**Basic profile:** advancing into some high-leverage role in government (or some other institution such as the World Bank), from which you can help the larger institution make decisions that are good for the long-run future of the world.

While [organization-supporting aptitudes](https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice#_Organization_building__running__and_boosting__aptitudes_1_) are mostly (in the long run) about helping some organization whose mission you're aligned with accomplish its existing goals, political and bureaucratic aptitudes are more about using a position of influence (or an influential network) to raise the salience and weight of longtermist goals within an institution.

Essentially any career that ends up in an influential position in some government (including executive, judicial, and legislative positions) could qualify here (though of course some are more likely to be relevant than others).

**Examples:**

Richard Danzig (former Secretary of the Navy, author of [Technology Roulette](https://www.cnas.org/publications/reports/technology-roulette)); multiple people who are pursuing degrees in security studies at Georgetown and aiming for (or already heading into) government roles.

A possible question to ask yourself: "What's an institution where I could imagine myself being relatively [[happy]], [[productive]], and motivated for a long time while 'playing by the institution's rules?'" I'd suggest speaking with later-[[career]] people at the institution to get as detailed a sense as possible of how long it will take to reach the kind of position you're hoping for; what your day-to-day life will be like in the meantime; and what you will need to do to succeed.

Sometimes the best way to advance will involve going somewhere other than the institution itself, temporarily (e.g., law school, public policy school, think tanks).

I think one of the main questions for this sort of aptitude is "How sustainable does this feel?" This question is relevant for all aptitudes, but especially here - for political and bureaucratic roles, one of the main determinants of how well you advance is simply how long you stick with it and how consistently you meet the institution's explicit and implicit expectations.
## "Conceptual and empirical [[research]] on core longtermist topics" aptitudes

**Basic profile:** helping to reach correct substantive conclusions on action-relevant questions for effective altruists, such as:
- Which causes are most promising to work on? (This could include things like making the case for longtermism)
- What's a reasonable probability distribution over things like (a) when transformative AI will be developed; (b) the size of various existential risks?
- What can we learn from historical cases about the most promising routes to growing the effective altruist community?
- What policy changes would be most desirable to push for in order to reduce existential risk?
- How should money be allocated between potential grantees in a given cause (or generally)? (And how should it be allocated across time, i.e., "giving now vs. giving later?")
- What sorts of jobs should effective altruists be most encouraged to aim for?
  
  **Examples:**
- Eliezer Yudkowsky, Nick Bostrom, and others who have worked to flesh out the case for prioritizing existential risk and AI safety in particular.
- Most people in research roles at FHI.
- Most people in research roles at Open Philanthropy (you could also think of the grantmaking roles this way).
- People working on determining what 80,000 Hours's substantive recommendations and advice should be (as opposed to how to communicate it).
  
  Note that some people in this category do mostly conceptual/philosophical work, while some do mostly empirical work; some focus on generating new hypotheses, while others focus on comparing different options to each other. The unifying theme is of focusing on reaching **substantively correct conclusions**, not on better communicating conclusions others have reached.
  
  I think other jobs are promising as well for developing key tools, habits, and methods:
- [[Academic]] study in fields that are relevant for the kinds of questions you want to work on. It's hard to generalize very far here, but for conceptual questions, I think [[philosophy]], [[mathematics]], [[computer scienc]]e, and theoretical [[physics]] are especially promising; for more empirical questions, [[economics]] seems most generally promising, since fluency with quantitative social science seems important. (Many other areas, such as [[history]] and political science, could be useful as well.)
- Jobs that heavily feature making difficult intellectual [[judgment]] calls and [[bets]], preferably on topics that are “macro” and/or as related as possible to the questions you’re interested in. There are some jobs like this in "buy-side" finance (trying to predict markets) and in politics (e.g. [BlueLabs](https://bluelabs.com/who-we-are/about-us/)).
  
  I also think there are opportunities to explore and demonstrate these aptitudes via **self-study and independent work** - on free time, and/or on scholarships designed for this (such as [EA Long-Term Future Fund grants](https://docs.google.com/forms/d/e/1FAIpQLScdg63O8i7N2HR4LCJeqF0G7OYqEtyLlZ5kvZzvqUqXebmV9w/viewform), [Research Scholars Program](https://www.fhi.ox.ac.uk/rsp/), and [Open Philanthropy support for individuals working on relevant topics](https://www.openphilanthropy.org/focus/other-areas/early-career-funding-individuals-interested-improving-long-term-future)).
## Trying an aptitude out

The basic formula I see for trying out these aptitudes for self-study is something like:
- Examine some effective-altruism-related [[hypothesis]] or question, and get very deep into it, forming your own "inside" view (a view based on your own reasoning and [[logic]], rather than reasoning based on what others believe).
- Write up your view with strong [reasoning transparency](https://www.openphilanthropy.org/reasoning-transparency), somewhere such as LessWrong or the EA Forum.
- Engage in discussion.
  
  Some example approaches:
- Closely and critically review some piece of writing and argumentation on longtermist topics. This could be a highly influential piece of writing such as [Astronomical Waste](https://www.nickbostrom.com/astronomical/waste.html), [On the Overwhelming Importance of Shaping the Far Future](https://rucore.libraries.rutgers.edu/rutgers-lib/40469/PDF/1/play/), some chapter of [Superintelligence](https://smile.amazon.com/dp/B00LOOCGB2/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1) or [The Precipice](https://smile.amazon.com/dp/B07VB299G3/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1), various pieces on [[AI]] timelines, etc. Or for an easier start, it might be a recent post from the EA Forum, AI Alignment Forum, LessWrong, or a particular blog you think talks about interesting topics. Explain the parts you agree with as clearly as you can, and/or explain one or more of your key disagreements.
- Pick some question such as "What are the odds of existential catastrophe this century?" (very broad) or "What are the odds of nuclear winter this century?" (narrower, likely more tractable). [[write]] up your current view and reasoning on this, and/or [[write]] up your current view and reasoning on some sub-question that comes up as you're [[thinking]] about it.[[2(https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists?utm_source=80%2C000+Hours+mailing+list&utm_campaign=4f086184e8-RESEARCHNEWSLETTER_Oct_2021_1&utm_medium=email&utm_term=0_43bc1ae55c-4f086184e8-352106301#fn-aAvgmw6MqeiaihsEj-2)
- Look into some question that's been explicitly flagged as a "question for further investigation" (e.g. [here](https://www.openphilanthropy.org/blog/technical-and-philosophical-questions-might-affect-our-grantmaking) or [here](https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit#heading=h.1ewyaoago2z6)). Try to identify some sub-question you can shed some light on, and write up what you find.
  
  It could also be beneficial to start with somewhat more concrete, tractable versions of this sort of exercise, such as:
- Explaining/critiquing interesting arguments made on any topic you find motivating to write about.
- Making bets and/or forecasts on PredictIt, GJOpen or Metaculus and explaining your thinking.
- Writing [fact posts](https://www.lesswrong.com/posts/Sdx6A6yLByRRs8iLY/fact-posts-how-and-why).
- Closely examining and explaining and/or critiquing [GiveWell's](https://www.givewell.org/) recommendations and [cost-effectiveness analyses](https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness/cost-effectiveness-models), or [GPI's](https://globalprioritiesinstitute.org/) papers (all of these are publicly available and tend to explain their reasoning thoroughly).
- Reviewing the academic literature on any topic of interest and trying to reach and explain a bottom-line conclusion (there are many examples of this sort of exercise in Slate Star Codex's ["more than you wanted to know" tag](https://slatestarcodex.com/tag/much-more-than-you-wanted-to-know/); researching medical questions of personal interest can be an easy way to find topics).
  
  It could also be beneficial to start with somewhat more concrete, tractable versions of this sort of exercise, such as:
- Explaining/critiquing interesting arguments made on any topic you find motivating to write about.
- Making [[bets]] and/or forecasts on PredictIt, GJOpen or Metaculus and explaining your [[thinking]].
- [[Writing]] [fact posts](https://www.lesswrong.com/posts/Sdx6A6yLByRRs8iLY/fact-posts-how-and-why).
- Closely examining and explaining and/or critiquing [GiveWell's](https://www.givewell.org/) recommendations and [cost-effectiveness analyses](https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness/cost-effectiveness-models), or [GPI's](https://globalprioritiesinstitute.org/) papers (all of these are publicly available and tend to explain their reasoning thoroughly).
- Reviewing the academic literature on any topic of interest and trying to reach and explain a bottom-line conclusion (there are many examples of this sort of exercise in Slate Star Codex's ["more than you wanted to know" tag](https://slatestarcodex.com/tag/much-more-than-you-wanted-to-know/); researching medical questions of personal interest can be an easy way to find topics).
  
  Some example milestones you could aim for while developing these aptitudes:
- You’re successfully devoting time to this and creating content. (I expect this to be the hardest milestone to hit for many - it can be hard to simply sustain motivation and productivity given how self-directed this work often needs to be.)
- In your own judgment, you feel you have made and explained multiple novel, valid, nontrivially important (though not necessarily earth-shattering) points about crucial longtermist topics.
- You’ve gotten enough feedback (upvotes, comments, personal communication) to feel that at least several other people (whose judgment you respect, and who put serious time into thinking about these topics) agree.
- You’re making meaningful connections with others interested in these topics - connections that seem likely to lead to further funding and/or job opportunities. This could be from the organizations most devoted to your topics of interest; there could also be a "dissident" dynamic in which these organizations seem uninterested and/or defensive, but others are noticing this and offering help.
  
  My very rough impression/guess is that for people who are an excellent good fit for this aptitude, a year of full-time independent effort should be enough to mostly reach these milestones, and that 2-3 years of 20%-time independent effort (e.g., one day per week) should also suffice.
## "Communicator" aptitudes

**Basic profile:** helping to communicate key, substantively well-grounded messages and ideas to particular audiences. The audiences could be very general (e.g., writing for mass-market media) or more specialized (e.g., writing for policymakers on particular issues). Example messages could be the importance of global catastrophic risks, the challenge of AI alignment, the danger of covert state bioweapons programs, the general framework of effective altruism, and many more.

**Examples:**
- Kelsey Piper and other journalists at [Future Perfect](https://www.vox.com/future-perfect/2018/10/15/17924288/future-perfect-explained).
- Authors of mass-market books such as [The Alignment Problem](https://smile.amazon.com/dp/B085T55LGK/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1).
- People who do social media and/or podcasting, e.g. Julia Galef and Rob Wiblin.
- People working at think tanks, whose main goal is to put key ideas in terms that will be more compelling to particular policymaking audiences.
  
  **How to try developing these aptitudes:**
  
  First, you should have some idea of what sort of **target audience** you’d like to communicate with. A possible question to ask yourself: "What's a type of person that I understand and communicate with, better than most EAs / longtermists do?"
  
  Then, you can try to get any job that involves communicating with this audience and getting feedback on a regular basis - whether or not the communication is about EA/longtermist topics.
  
  I also think there's a lot of opportunity to build this sort of aptitude through independent work, such as blogging, tweeting, podcasting, etc. I expect that some of the people with the greatest potential as communicators are those who find it relatively easy to create large amounts of content and connect with their target audience naturally.
## Academia

**Basic profile:** following an academic career track likely means picking a field relatively early, earning a Ph.D., continuing to take academic positions, attempting to compile an impressive publication record, and ultimately likely aiming for a role as a tenured professor (although there are some other jobs that recruit from academia). Academia is a pretty self-contained career track, so this is a case where there isn't a lot of difference between an "aptitude" and a "path" as defined in the introduction of this post.

Being an academic could be useful for longtermist goals in a few ways:
- You might do research that relates substantively to key longtermist questions, which would cause this aptitude to overlap with ["conceptual and empirical research on core longtermist topics" aptitudes](https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice#_Conceptual_and_empirical_research_on_core_longtermist_topics__aptitudes).
- You might have opportunities to raise the profile of important longtermist ideas within your field. You could think of this as being a sort of specialized "[communicator](https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice#_Communicator__aptitudes)" role. ([Global Priorities Institute](https://globalprioritiesinstitute.org/) often aims for some combination of this point and the one above.)
- You might have opportunities to advise policymakers and the public, as an expert.
- You might have opportunities to help introduce your students to important longtermist ideas, including by teaching courses on effective altruism and longtermism ([example](https://www.openphilanthropy.org/giving/grants/university-of-michigan-support-for-david-manley)). (As a side note, I think there could also be a lot of potential impact in being a K-12 teacher who looks for opportunities to introduce students to important ideas in effective altruism and longtermism.)
- Additionally, some academic fields open doors for potentially high-impact non-academic roles. AI is perhaps the best example: studying AI and having impressive early-career accomplishments (even prior to earning one's PhD) can be a good way to end up with a "scientist" role at a private AI lab. Economics also can lead to strong non-academic opportunities, including in policymaking.
  
  Many academic fields could potentially lead to these sorts of opportunities. Some that seem particularly likely to be relevant for longtermists include:
- AI
- [[Biology]], epidemiology, public health, and other fields relevant to biorisk
- Climate science
- Economics and philosophy, the two priority fields at [Global Priorities Institute](https://globalprioritiesinstitute.org/)
  
  **Examples:**
  
  Hilary Greaves at Global Priorities Institute; Stuart Russell at Center for Human-Compatible AI; [Kevin Esvelt](https://www.media.mit.edu/people/esvelt/overview/).
  
  **How to try developing this aptitude:**
  
  The academic career path is very well-defined. People entering it tend to have fairly robust opportunities to get advice from people in their field about how to advance, and how to know whether they're advancing.
  
  In general, I would encourage people to place high weight on succeeding by traditional standards - both when picking a field and when picking topics and projects within it - rather than trying to optimize too heavily for producing work directly relevant to longtermist goals early in their careers.
# Hybrid aptitudes

Sometimes people are able to do roles that others can't because they have two (or more) of the sorts of aptitudes listed above. For example, perhaps someone is a reasonably strong [software engineer](https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice#Software_engineering_aptitude) _and_ a reasonably strong [project/people manager](https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice#_Organization_building__running__and_boosting__aptitudes_1_), which allows them to contribute more as a software engineering manager than they could as either a software engineer or a nontechnical manager. In the effective altruism community, ["conceptual and empirical research"](https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice#_Conceptual_and_empirical_research_on_core_longtermist_topics__aptitudes) often goes hand in hand with "[communicator](https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice#_Communicator__aptitudes)" (as with Nick Bostrom writing _Superintelligence_).

I think it's good to be open to building hybrid aptitudes, but also good to keep in mind that specialization is powerful. I think the ideal way to pursue a hybrid aptitude is to start with one aptitude, and then notice an opportunity to develop another aptitude that complements it and improves your career options. I wouldn't generally recommend pursuing multiple aptitudes at once early in one's career.
- # How to choose an aptitude
  
  I imagine some people will want a take on which of these aptitudes is "highest [[impact]]."
  
  My main opinion on this is that variance within aptitudes probably mostly swamps variance between them. Anyone who is an outstanding, one-of-a-kind talent at any of the aptitudes I listed is likely having enormous expected impact; anyone who is successful and high-performing is likely having very high expected impact; anyone who is barely hanging onto their job is likely having less impact than the first two categories, even if they're in a theoretically high-impact role.
  
  I also believe that successfully building an aptitude - to the point where one is "professionally in demand" - generally requires sticking with it and putting a lot of time in for a long time. Because of this, I think people are more likely to succeed when they enjoy their work and thrive in their work environment, and should put a good deal of weight on this when considering what sorts of aptitudes they want to build. (I think this is particularly true early in one's career.)[[6(https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists#fn-aAvgmw6MqeiaihsEj-6)
  
  With these points in mind, I suggest a couple rules of thumb that I think are worth placing some weight on:
  
  1.  "Minimize N, where N is the number of people who are more in-demand for this aptitude than you are." A more informal way of putting this is "Do what you'll succeed at."
  2.  "Take your intuitions and feelings seriously." A lot of people will instinctively know what sorts of aptitudes they want to try next; I think going with these instincts is usually a good idea and usually shouldn't be overridden by impact estimates. (This doesn't mean I think the instincts are usually "correct." I think most good careers involve a lot of experimentation, learning that some sort of job isn't what one pictured, and changing course. I think people learn more effectively when they follow their curiosity and excitement; this doesn't mean that their curiosity and excitement are pointing directly at the optimal ultimate destination.)