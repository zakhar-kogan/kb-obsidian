- [[associative data]] [[graphs]]
- https://iacis.org/iis/2009/P2009_1301.pdf
	- Two of the relatively well-known database models are the ==hierarchical and network models.== Hierarchical models involve “a data structure in which the elements of the structure have only one-to-many relationships with one another”
		- ![image.png](../assets/image_1668714435236_0.png)
	- Similarly, Kroenke [11] defines a network database structure is one “in which at least one of the
	  relationships is many-to-many.”
		- ![image.png](../assets/image_1668714473250_0.png)
	- One of the most commonly used database structures is the ==relational database model==. As the name implies the relational database model “has the relation at its heart, but then a whole series of rules governing keys, relationships, joins, functional dependencies, transitive dependencies, multi-valued dependencies, and modification anomalies” [14 The Relational Data Model, para. 1].
		- ![image.png](../assets/image_1668714513811_0.png)
		- ![image.png](../assets/image_1668714526333_0.png)
	- Normalization is a major challenge in RDBMS design. Kroenke [10] defines normalization as “a
	  process for converting a relation that has certain problems to two or more relations that do not have these problems.” Much is written about tips for normalizing a database and many authors note that an RDBMS is not the best database design for all types of data. Even in more recent writings by the father of the RDBMS, Codd [5] admits that a “relational database is best suited to data with a rather regular or homogeneous structure” and that more research is needed to determine if an RDBMS can sufficiently handle “heterogeneous data” such as “images, text, and miscellaneous facts.”
	- The ==associative database model== is claimed to offer advantages over RDBMS and other database models. While an RDBMS and other database models are record-based – with data stored in rows and columns in tabular representations shown in figures 4 and 5 – all data in the associative database model is modeled as discrete independent data elements.
	- Relationships between data elements are modeled as **associations**. Griffiths [7] describes these *“two fundamental data structures” as “„**Items**‟ and a set of „**Links**‟ that connect them together.”* Williams [17] introduces the associative database model as having two types of data structures, Items which have *“a unique identifier, a name and a type”* and Links which have *“a unique identifier, together with the unique identifiers of three other things, that represent the source, verb and target of a fact that is recorded about the source in the database.”* He further notes that *“each of the three things identified by the source, verb and target may each be either a link or an item.”*
		- ![image.png](../assets/image_1668716278247_0.png)
	- ![image.png](../assets/image_1668716319666_0.png)
	- ADBMS that may make it more attractive to future users is its inherent security features. The content (data) and index (associations) can be stored together or separately in different places. If a hacker were to access one or the other, Aysola [1] notes that “nothing more than an unlimited character string” is revealed.
- https://web.archive.org/web/20220518204118/https://link.springer.com/content/pdf/10.1057/palgrave.jdm.3240049.pdf
	- Brains do not need new thought
	  processes to think about new things —
	  why do computers? Every new relational
	  application needs a new set of programs
	  developed from scratch, because a
	  program written to use one set of tables
	  cannot be reused with a different set.
	  This creates a need for a never-ending
	  supply of new programs, the
	  development and maintenance of which
	  is labour-intensive, expensive and
	  wasteful
	- Users do not all need the same
	  functions — why is customisation so
	  difficult? Relational applications offered
	  by ASPs (Application Service Providers)
	  and package vendors can only be tailored
	  to the needs of large numbers of
	  individual users through complex
	  parameterisation or through customisation
	  which renders subsequent upgrades more
	  difficult. Finding a way to support the
	  customisation of applications for
	  individual users is one of the main challenges faced by early players in the
	  burgeoning ASP marketplace.
	- All customers are not the same —
	  why store the same information about
	  each one? Relational applications cannot
	  record a piece of information about an
	  individual thing that is not relevant to
	  every other thing of the same type.
	  Consequently, applications have to store
	  the same information about every
	  customer, order, product and so on. This
	  limits marketers’ ability to continually
	  improve the quality of customer service,
	  because applications cannot record and
	  take account of the needs of individual
	  customers.
	- All databases store data — why can
	  they not work together more easily?
	  Information about identical things in the
	  real world is structured differently in
	  every relational database, so it is difficult
	  and expensive to amalgamate two
	  databases. The cost of integrating systems
	  is now a major impediment to mergers
	  and acquisitions. Extracting useful
	  information from across several databases
	  demands expensive data warehousing and
	  mining projects.
	- It is no longer necessary to write every
	  new application from scratch. The same
	  set of programs can be used to
	  implement many different associative
	  applications without being altered or
	  rewritten in any way, allowing users to
	  create new applications from existing
	  ones. The saving in software
	  development costs afforded by this
	  capability will be substantial.
	  Applications can be tailored for
	  individual users. Associative applications
	  can permit features to be used or ignored
	  selectively by individual users without
	  the need for parameterisation or customisation. Data sets can be similarly
	  partitioned with precise granularity, to be
	  visible or invisible to individual users.
	  This approach is ideally suited to the
	  needs of ASPs and application package
	  vendors alike.
	  The information needed about each
	  customer can be stored precisely. An
	  associative database can record
	  information that is relevant only to one
	  thing of a particular type, without
	  demanding that it be relevant to all other
	  things of the same type. With this
	  capability, we can continue to enhance
	  the quality of customer service and hone
	  competitive edge.
	  Databases can be integrated without
	  extra programming or data warehousing
	  tools. Separate associative databases can
	  be readily correlated or merged without
	  extra programming, and multiple
	  databases distributed across many servers
	  can be accessed by applications as though
	  they were a single database. These
	  capabilities significantly reduce the cost
	  of amalgamating databases, and allow
	  information to be readily extracted from
	  across multiple databases without the
	  need for data warehousing.
	- Many people who hear the term
	  ‘relational’ for the first time assume that it
	  derives from relationships between the
	  things stored in the database. In fact, it
	  comes from the mathematical concept of
	  a ‘relation’: ‘Given sets S1, S2, . . ., Sn, R
	  is a relation on these n sets if it is a set of
	  n-tuples, the first component of which is
	  drawn from S1, the second component
	  from S2, and so on’. The proper term for
	  the tables described here is ‘relations’.
	- Every new relational database application needs a new set of programs
	  written from scratch, because a program
	  written for one application cannot be
	  reused for another. This creates a need for
	  a never-ending supply of new programs,
	  the development of which is
	  labour-intensive, time-consuming and
	  expensive. Why is this so?
	  Programs are designed around tables.
	  Under the relational model, every table
	  is structured differently — that is, it has
	  different columns and column headings
	  — and the programs are designed around
	  the tables. It is impossible to write an
	  efficient program that is capable of
	  accessing a table whose structure is not
	  known when the program is written, just
	  as it is impossible to make a key that
	  will open any lock. Every program has
	  to be written by someone with precise
	  knowledge of the tables that it will use,
	  and a program that uses one set of tables
	  cannot be used with a different set. In
	  commercial applications, each entity type
	  — customers, products, orders and so on
	  — is represented by at least one table,
	  and most applications involve between
	  50 and 500 entity types, so each new
	  application needs somewhere between
	  500 and 5,000 new programs to be written from scratch.
	- One of the stated goals of
	  object-oriented programming was the
	  re-use of program code. Some 20 years
	  after the first object-oriented languages
	  were developed, however, almost no true
	  re-use has been achieved. Some
	  development tools automate the process
	  of writing programs by re-using program
	  designs, but such tools demand higher
	  levels of skill and training and thus
	  greater up-front investment than
	  traditional programming techniques, so
	  despite their impressive productivity
	  levels their use is not widespread. Most
	  programs developed today are still
	  hand-coded from scratch in a highly
	  labour-intensive manner. Re-use has
	  failed not because programming
	  languages and tools are deficient or
	  because programmers are not clever
	  enough, but simply because data are not
	  stored in a way that permits it
	- Parameterisation fuels complexity.
	  Historically, the behaviour of each
	  installation of an application package has
	  been determined by parameterisation: the application checks a set of parameter
	  values as it executes to determine
	  precisely how its code should behave.
	  This approach has drawbacks arising
	  from the exponential increase in
	  complexity as new options are added
	  over time. The code itself becomes
	  extremely complex: different pieces of
	  business logic need to check different
	  parameters to determine whether they
	  are invoked, and as the number of
	  options increases, new functions are
	  more difficult to add, and testing the full
	  range of configurations created by
	  different combinations of parameters
	  becomes more difficult. Also, deploying
	  the package becomes very costly for
	  customers. The lion’s share of the cost of
	  installing a sophisticated package goes on
	  the specialist assistance needed to
	  implement it. A major component of
	  this is the time and know-how involved
	  in setting up the package to achieve the
	  desired behaviour.
	- Modified packages are difficult to
	  upgrade to new releases. Users who
	  require functionality not provided by the
	  core package must modify their copy to
	  create the behaviour that they require.
	  This greatly increases the difficulty of
	  upgrading to new versions of the
	  package provided by the vendor, which
	  often contain important new
	  functionality that the customer would
	  wish to exploit. A small industry of
	  source code comparison, configuration
	  management and impact analysis skills
	  and tools exists to cater for precisely this
	  need, but even so, typically fewer than
	  50 per cent of major application package
	  users implement new releases for this
	  reason.
	-